# -*- coding: utf-8 -*-
"""Demo.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qyt6trIkcAbSbIw-d--9RVD_pY6xa6Xc
"""

import pandas as pd
from pandas import DataFrame

import matplotlib.pyplot as plt
import seaborn as sns

import numpy as np

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

from sklearn.model_selection import cross_val_score
from sklearn.metrics import f1_score, make_scorer
from sklearn.preprocessing import OneHotEncoder, FunctionTransformer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.model_selection import GridSearchCV

from sklearn.tree import DecisionTreeClassifier

"""В файлах Data_train.csv и Data_test.csv находятся данные о кошках.

В этом задании предлагается изучить поведение диких и домашних кошек на основе нескольких характеристик. О кошках имеется некоторая базовая информация (type, group). У кошек были инструкторы. Инструктор обеспечивает кошку питанием, а некоторых кошек обучает проходить полосу препятствий (некоторых - не обучает). Результаты прохождения полосы препятствий оценивались независимо тремя судьями по стобалльной шкале.

Описание столбцов:

* type - тип кошки: дикая (wild) или домашняя (domestic)

* group - закодированная возрастная группа кошки

* education - уровень подготовки инструктора

* meal - тип рациона кошки

* preparation course - обучалась ли кошка прохождению полосы препятствий (проходила ли специальный курс)

* score-1 - балл первого судьи за прохождение кошкой полосы препятствий

* score-2 - балл второго судьи за прохождение кошкой полосы препятствий

* score-3 - балл третьего судьи за прохождение кошкой полосы препятствий

Далее за задания можно получить максимум 4 балла.


Считайте данные в два pandas dataframe: df_train и df_test.

Задание 1 (0.25 балла). Заполните пропуски в столбце уникальной категорией, если столбец с пропуском категориальный, и средним значением, если столбец числовой. Заполняйте одновременно и df_train, и df_test - одинаковым образом. В ответе укажите количество различных значений, потребовавшихся для заполнения пропусков (это равно количеству новых уникальных категорий плюс количество средних значений для заполнения пропусков в числовых столбцах).
"""

train_data = pd.read_csv("Data_train.csv")
test_data = pd.read_csv("Data_test.csv")

train_data.head()

test_missing = test_data.isnull().sum()
train_missing = train_data.isnull().sum()

print("TrainData Missing:\n", train_missing)
print('\n')
print("TestData Missing:\n", test_missing)

categorical_columns = train_data.select_dtypes(include=['object']).columns
for col in categorical_columns:
  train_data[col].fillna("UniqueCategory", inplace=True)

categorical_columns = test_data.select_dtypes(include=['object']).columns
for col in categorical_columns:
  test_data[col].fillna("UniqueCategory", inplace=True)

numeric_columns = train_data.select_dtypes(include=['int64', 'float64']).columns
for col in numeric_columns:
  train_data[col].fillna(train_data[col].mean(), inplace=True)

numeric_columns = test_data.select_dtypes(include=['int64', 'float64']).columns
for col in numeric_columns:
  test_data[col].fillna(test_data[col].mean(), inplace=True)

"""Задание 2 (0.3 баллов). Кошка прошла полосу препятствий по мнению судьи, если он поставил ей больше 50 баллов. Кошка считается прошедшей полосу препятствий, если все судьи поставили ей больше 50 баллов. В df_train создайте колонку 'Pass' и запишите в неё 1, если кошка прошла полосу препятствий, и 0 иначе. В ответ запишите, сколько кошек из df_train не прошли полосу препятствий.

В df_test от вас скрыта информация о судейских баллах, поэтому неизвестно, прошла кошка полосу препятствия или нет - это и надо будет предсказать в заданиях ниже.
"""

train_data['Pass'] = (train_data['score-1'] > 50) & (train_data['score-2'] > 50) & (train_data['score-3'] > 50)
train_data['Pass'] = train_data['Pass'].astype(int)

print((train_data['Pass'] == 0).sum())

"""Задание 3 (каждый пункт - 0.25 балла, 1.25 балла максимум).

Это задание выполняйте по данным df_train.

1) Среди всех диких кошек найдите долю кошек, прошедших полосу препятствий. Такую же долю рассчитайте для домашних кошек. В ответе укажите модуль разности этих долей. Ответ округлите до сотых.
"""

wild_pass_count = train_data[(train_data['type'] == 'wild') & (train_data['Pass'] == 1)].shape[0]
wild_total_count = train_data[train_data['type'] == 'wild'].shape[0]
wild_pass_fraction = wild_pass_count / wild_total_count

dom_pass_count = train_data[(train_data['type'] == 'domestic') & (train_data['Pass'] == 1)].shape[0]
dom_total_count = train_data[train_data['type'] == 'domestic'].shape[0]
dom_pass_fraction = dom_pass_count / dom_total_count

print(round(abs(wild_pass_fraction - dom_pass_fraction), 2))

""" Сколько кошек среди не прошедших полосу препятствий имели инструктора с уровнем образования "high school"?

"""

cat_count = train_data[(train_data['education'] == 'high school') & (train_data['Pass'] == 0)].shape[0]
print(cat_count)

"""Сколько диких кошек среди прошедших полосу препятствий не проходили специальный курс подготовки?"""

wild_cat_count = train_data[(train_data['type'] == 'wild') & (train_data['Pass'] == 1) & (train_data['preparation course'] == 'none')].shape[0]
print(wild_cat_count)

"""Чему равна медиана баллов, выставленных первым судьей?"""

first_judge_median = train_data['score-1'].median()
print(first_judge_median)

"""Найдите межквартильный размах баллов третьего судьи (третья квартиль минус первая квартиль) для домашних кошек, не проходивших специальный курс подготовки.

Комментарий: для вычисления квартилей дискретного распределения используйте интерполяцию меньшим значением (lower interpolation). Это означает, что если искомая квартиль лежит между двумя измерениями i и j, то значение квартили равно i.
"""

filtered_cats = train_data[(train_data['type'] == 'domestic') & (train_data['preparation course'] == 'none')]

q1 = filtered_cats['score-3'].quantile(0.25, interpolation='lower')
q3 = filtered_cats['score-3'].quantile(0.75, interpolation='lower')

iqr = q3 - q1

print(iqr)

"""a) (0.3 баллa). Далее используйте только категориальные столбцы. Закодируйте их с помощью One-hot encoding с учетом того, что мы не хотим получить мультиколлинеарности в новых данных. Сколько получилось числовых столбцов из исходных категориальных? Кодируйте и df_train, и df_test."""

categorical_cols = train_data.select_dtypes(include=['object']).columns
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore', drop='first'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('cat', categorical_transformer, categorical_cols)
    ])
train_data_encoded = preprocessor.fit_transform(train_data)
test_data_encoded = preprocessor.transform(test_data)
count_numeric_columns = train_data_encoded.shape[1]

print(count_numeric_columns)

"""Попытаемся по характеристикам кошки (бывшие категориальные, а теперь - числовые столбцы) предсказать, прошла она полосу препятствий или нет.


Сформируйте из df_train матрицу объект-признак X и вектор ответов y.


Обучите решающее дерево (DecisionTreeClassifier из библиотеки sklearn.tree) глубины 5 с энтропийным критерием информативности на закодированных в пункте а) тренировочных данных по кросс-валидации с тремя фолдами, метрика качества - roc-auc.


Чему равен roc-auc, усредненный по фолдам? Ответ округлите до десятых.


Комментарий: остальные гиперпараметры дерева оставьте дефолтными (splitter='best', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0)
"""

X = train_data_encoded
y = train_data['Pass']

clf = DecisionTreeClassifier(max_depth=5, criterion='entropy', random_state=42)
cv_scores = cross_val_score(clf, X, y, cv=3, scoring='roc_auc')

mean_roc_auc = cv_scores.mean()
print(round(mean_roc_auc, 1))

"""
a) (0.25 балла). Подберите глубину решающего дерева (max_depth), перебирая глубину от 2 до 20 с шагом 1 и используя перебор по сетке (GridSearchCV из библиотеки sklearn.model_selection) с тремя фолдами и метрикой качества - roc-auc. В ответ запишите наилучшее среди искомых значение max_depth.


Комментарий: остальные гиперпараметры дерева оставьте дефолтными (splitter='best', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, ccp_alpha=0.0)"""

param_grid = {'max_depth': range(2, 21)}
grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, scoring='roc_auc')
grid_search.fit(X, y)

print(grid_search.best_params_['max_depth'])

"""Добавьте к данным новый признак cat_bio, содержащий в качестве значений пары значений из столбца type и столбца group. Например, если кошка имеет type='wild' и  group='group B', то в cat_bio будет стоять строка '(wild, group B)'. Примените OneHotEncoding (с учетом того, что мы не хотим получить мультиколлинеарности в новых данных) к столбцам 'cat_bio', 'education', 'meal', 'preparation course', а затем обучите решающее дерево глубины 5 с энтропийным критерием информативности на полученных после кодирования данных. Чему равен roc-auc? Ответ округлите до сотых.

Теперь вы можете использовать любую модель машинного обучения для решения задачи. Также можете делать любую другую обработку признаков. Ваша задача - получить наилучшее качество (ROC_AUC).

Качество проверяется на тестовых данных.

ROC_AUC > 0.7 - 0.25 балла
ROC_AUC > 0.74 - 0.75 балла
Сдайте файл result.txt: в файле должна одна колонка с предсказанными значениями целевой переменной для тестовой выборки, без индекса и заголовка.
Во вложении пример файла для отправки результатов.
"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV

# Определим модель
gb_classifier = GradientBoostingClassifier()

# Определим сетку параметров для подбора
param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.5],
    'max_depth': [3, 5, 7]
}

categorical_features = train_data.select_dtypes(include=['object']).columns
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', categorical_transformer, categorical_features)
    ])

# Определим объект GridSearchCV
grid_search = GridSearchCV(gb_classifier, param_grid, cv=5, scoring='roc_auc')

# Обучим GridSearch на обучающих данных
grid_search.fit(X_train, y_train)

# Получим наилучшие параметры модели
best_params = grid_search.best_params_

# Выведем наилучшие параметры
print("Best Parameters:", best_params)

# Получим наилучшую модель
best_gb_classifier = grid_search.best_estimator_

# Обучим наилучшую модель на обучающих данных
best_gb_classifier.fit(X_train, y_train)

# Сделаем прогнозы на тестовых данных
y_pred = best_gb_classifier.predict_proba(X_test)[:, 1]

# Вычислим ROC-AUC
roc_auc = roc_auc_score(y_test, y_pred)
print("ROC-AUC:", round(roc_auc, 2))